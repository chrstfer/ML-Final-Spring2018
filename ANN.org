# -*- org-confirm-babel-evaluate: nil; -*-
#+AUTHOR: Chris Carrigan Brolly
#+TITLE: Artificial Neural Nets 
#+HTML_HEAD: <link href="http://gongzhitaao.org/orgcss/org.css" rel="stylesheet" type="text/css" />
#+PROPERTY: header-args :session ANNimpl

* Setup
** R Setup  
*** Libraries and Functions
  #+BEGIN_SRC R :results none :export source
    library(sigmoid)
    getLabels <- function(lbldb, nget=0) {
	magic  <- readBin(lbldb, what="integer", n=1, endian="big", size=4)
	if(magic != 2049)
	    return(NULL)
	n.lbls    <- readBin(lbldb, what="integer", n=1,    endian="big", size=4)
	if(nget==0)
	    nget=n.lbls

	labels <- readBin(lbldb, what="integer", n=nget, endian="big",  size=1)

	close(lbldb)
	return(labels)
    }

    getImages <- function(imgdb, nget=0, progress=FALSE) {
	magic  <- readBin(imgdb, what="integer", n=1, endian="big", size=4)
	## if(magic != 2049)
	##     return(NULL)

	n.imgs <- readBin(imgdb, what="integer", n=1, endian="big", size=4)
	if(nget==0)
	    nget <- n.imgs # trunc(sqrt(n.imgs))

	n.rows <- readBin(imgdb, what="integer", n=1, endian="big", size=4)
	n.cols <- readBin(imgdb, what="integer", n=1, endian="big", size=4)

	print(gettextf("Getting %d %dx%d Images", nget, n.rows, n.cols))

	images <- c()
	for(i in 1:nget) {
	    .img   <- matrix(readBin(imgdb, what="integer", n=n.rows*n.cols, endian="big", size=1), nrow=n.rows, ncol=n.cols)
	    images <-  c(images, list(.img))
	    if(progress && i %% trunc(sqrt(nget)) == 0) 
		print(gettextf("%2.2f%%", round((100*i)/nget, digits=2)))
	}
	close(imgdb)
	return(images)
    }
  #+END_SRC


** Data Setup
*** Data (Links)
  |---------------------+----------+-------------------------------------------------------------|
  | ID                  | size (b) | Link                                                        |
  |---------------------+----------+-------------------------------------------------------------|
  | training set images |  9912422 | http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz |
  | training set labels |    28881 | http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz |
  | test set images     |  1648877 | http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz  |
  | test set labels     |     4542 | http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz  |
  |---------------------+----------+-------------------------------------------------------------|

*** Data (import)
  tr.files.imgs <- "datasets/training/images"
  tr.files.lbls <- "datasets/training/labels"
  ts.files.imgs <- "datasets/testing/images"
  ts.files.lbls <- "datasets/testing/labels" 


#+BEGIN_SRC R :results output graphics :file imgs/setup/ex1.png
  ## Works
  tr.labels <- as.vector(getLabels(gzfile("datasets/training/labels", "rb"), nget=256))
  tr.images <- getImages(gzfile("datasets/training/images", # data's filename
				"rb"), # read it as binary
			 ## Get 256 of the entries
			 nget=256, progress=TRUE)
  tr.im.matrix <- do.call("rbind", # create rows out of the input data
			  lapply(tr.images, as.vector)) # transform each image
							# matrix into a vector

  tr.df <- cbind(tr.im.matrix, tr.labels) # now create a data frame

  oldpar <- par(mar=rep(0,4))
  image(tr.images[[8]], useRaster=TRUE, col=seq(2^8)) 
  par(oldpar)

#+END_SRC

#+RESULTS:
[[file:imgs/setup/ex1.png]]


#+BEGIN_SRC R :results table drawer :colnames yes
  table(Labels=tr.df[,ncol(tr.df)])
  ## sprintf("Row x Col: %d x %d", nrow(tr.df), ncol(tr.df))
#+END_SRC

#+RESULTS:
:RESULTS:
| Labels | Freq |
|--------+------|
|      0 |   30 |
|      1 |   35 |
|      2 |   25 |
|      3 |   30 |
|      4 |   24 |
|      5 |   17 |
|      6 |   24 |
|      7 |   26 |
|      8 |   19 |
|      9 |   26 |
:END:


* Implementation: Multilayer Perceptron with Backprop
- Features ::
  - builds arbitrarily layered ANN model
  - has weights (rnorm), biases(rnorm), and layer nodes
  - has member function for layer extraction
    - returns class "layer" with 3 member lists for the given layers data
- TODO ::
  - predict function :: feedforward (recursive chain of feedforwardstep?)
  - train function ::   backprop (step then recursive chain?)
  - summary functions :: layer and model
  - print functions :: layer, model
  - plot functions :: model, inputs, outputs (eg plot the input rows of tr.df,
                      and output of predict

** Model Class
#+BEGIN_SRC R :exports both :results output
  summary.model.ann.classifier <- function(model) {
      print(paste("Number of Layers: ", model$nlayers))
      print(paste("Respective Lengths: ", toString(model$lengths)))
  }

  summary.layers <- function(layers) {
      lapply(X=layers, summary)
  }

  ## print.layer <- function(layer) {
  ##     cat("\n")    
  ## }

  model.gen.annc <- function(length.input,
                             length.hidden,
                             length.output,
                             out.classes=as.factor(1:length.output),
                             input=NULL) {    
      model <- list()
      class(model) <- "model.ann.classifier"

      lengths <- c(length.input,
                   length.hidden,
                   length.output)
      ## print(lengths)
      n.layers <- length(lengths)


      ## print(paste("Input Length:",     length.input))
      print(paste("Number of Layers:", n.layers))
      print(paste("Layer Lengths:",    toString(lengths)))
      ## print(paste("Output Length:",    length.output))

      model$nlayers <- n.layers
      model$lengths <- lengths

      .nodes <- lapply(1:n.layers,
                       function(n)
                           matrix(0,
                                  nrow=lengths[n],
                                  ncol=1))    
      model$nodes <- .nodes

      model$weights <- lapply(1:(length(model$nodes)-1),
                              function(k)
                                  matrix(rnorm(lengths[k+1]),
                                         nrow=lengths[k+1],
                                         ncol=lengths[k]))

      model$biases <- lapply(1:(length(model$nodes)-1),
                              function(k)
                                  matrix(rnorm(lengths[k+1]),
                                         nrow=lengths[k+1]))

      model$input <- if(length(input))
                         as.matrix(input)
                     else
                         .nodes[[1]]

      model$nodes[[1]] <- model$input

      model$get_layer <- function(k, .model=model) { ## 1 -> k=nlayers->output=nodes[[n]]
          ret <- list()
          class(ret) <- "layer"
          ret$nodes  <- .model$nodes[k]
          ret$weights<- ifelse(k==1, 0, .model$weights[k-1])
          ret$biases <- ifelse(k==1, 0, .model$biases[k-1])        
          return(ret)
      }

      return(model)
  }

  activate <- function(node) {
      return(lapply(node,
                    function(k)
                        exp(k)/(1+exp(k))))
  }
                       
  forwardstep <- function(model, k) {
      if(k==2)
          model$nodes[[k]] <- activate(model$weights[[k-1]]%*%model$input)
      else
          model$nodes[[k]] <- activate(model$weights[[k-1]]%*%model$nodes[[k-1]])
      return(model)
  }

  predict.model.ann.classifier <- function(model, input) {
      # Feed forward
      forwardstep(model, 2:model$nlayers)
      prediction <- activate(model$nodes[[nlayers]])
      return(prediction)
  }


  ## basic layout, 4 layers of 5x1
  model <- model.gen.annc(2,2,1, input=rbinom(n=2, size=1, prob=0.5))
  names(model)
  print(model$get_layer(1))
#+END_SRC

#+RESULTS:
#+begin_example
[1] "Number of Layers: 3"
[1] "Layer Lengths: 2, 2, 1"
[1] "nlayers"   "lengths"   "nodes"     "weights"   "biases"    "input"    
[7] "get_layer"
$nodes
$nodes[[1]]
     [,1]
[1,]    0
[2,]    1


$weights
[1] 0

$biases
[1] 0

attr(,"class")
[1] "layer"
#+end_example


#+RESULTS:
: TRUE

* Analysis
#+BEGIN_SRC R
 
#+END_SRC

* Conclusion



* Sources
** Biblio
   These I read in the process of completing this project. In places where
   specific citations could be made, I have places them and linked here. 

- https://journal.r-project.org/archive/2010-1/RJournal_2010-1_Guenther+Fritsch.pdf
- https://en.wikipedia.org/wiki/Perceptron
- https://cran.r-project.org/web/packages/sigmoid/sigmoid.pdf
